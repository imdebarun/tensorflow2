{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJWyiFbUVKeBkRrGqL+EDE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imdebarun/tensorflow2/blob/main/Neural_Network_Regression_with_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Regression with Neural Network in Tensorflow :\n",
        "There are many definitions for a regression problem but in our case, we are going to simplify it: predicting a numerical variable based on some other comination of variables, even shorter...predicting a number."
      ],
      "metadata": {
        "id": "yg0RhoNIBI1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter & Typical value :\n",
        "* Input layer shape - Same shape as number of input features\n",
        "* Hidden layer(s) - Problem specific, minimum = 1, maximum = unlimited\n",
        "* Neurons per hidden layer - Problem specific generally 10 to 100\n",
        "* Output layer shape - Same shape as desired prediction shape\n",
        "* Hidden Activation - Usually ReLU (rectified linear unit)\n",
        "* Output Activation - None, ReLU, logistic/tanh\n",
        "* Loss function - MSE (mean squared error) or MAE (mean absolute error) / Huber (combination of MAE/MSE) if outliers\n",
        "* Optimizer - SGD (Stochastic gradient descent), ADAM"
      ],
      "metadata": {
        "id": "ThDweAhjzL9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvYmEi9m_5Yo",
        "outputId": "1849d34d-e2dd-4086-e108-e64eea4b576d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating some data to view and fit -"
      ],
      "metadata": {
        "id": "6RWv8pW7B5Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features -\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels -\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it -\n",
        "plt.scatter(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "4r8J6NXZCFaU",
        "outputId": "c190e508-05b0-4056-8391-f39934db4dbb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f8527b8b1c0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y == X + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-QG0XsRCyaS",
        "outputId": "6f71e63c-7844-43c4-cf27-ff12cdeb6764"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input and Output shapes -"
      ],
      "metadata": {
        "id": "dObx5RslDQpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([937900])\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_HJZdRtDXlK",
        "outputId": "247ccb8d-be05-4353-c970-2b7f90c38f5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([937900], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our numpy arrays into tensors with dtype as float 32.\n",
        "X = tf.cast(tf.constant(X), dtype= tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype = tf.float32)\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3l13f5TDXh1",
        "outputId": "84165d8a-30a6-4470-d37b-9f35fa4a07e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC-RbId7DXfH",
        "outputId": "821b69b1-2290-4015-c008-e122cc535eff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps in modelling with Tensorflow -\n",
        "- **Creating a model** - define the input and output layers, as well as the layers of a deeplearning model.\n",
        "- **Compililng a model** - define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model)\n",
        "- **Fitting the model** - letting the model try to find patterns between X and y (features and labels)"
      ],
      "metadata": {
        "id": "HGDKSgFRTUHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add one extra dimension to the input value to become compataible with the model.\n",
        "X = tf.reshape(X, (-1, 1))"
      ],
      "metadata": {
        "id": "eOy39MbuwljG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 3. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"]) # mae is short form of mean absolute error\n",
        "\n",
        "# 4. Fit the model\n",
        "model.fit(X, y, epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_NIeAGYUYxD",
        "outputId": "fff89595-26a2-4379-d896-d2ea3a7de10b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 15.6480 - mae: 15.6480\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 15.3667 - mae: 15.3667\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 15.0855 - mae: 15.0855\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 14.8582 - mae: 14.8582\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 14.7257 - mae: 14.7257\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f8520e27550>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Optional methodology -\n",
        "# model = tf.keras.Sequential()\n",
        "# model.add(tf.keras.layers.Dense(1))"
      ],
      "metadata": {
        "id": "DBwbgUQtUYtw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIafJvUZxet7",
        "outputId": "08d35c5d-f42d-451f-d4e4-df277dd9c185"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
              " array([[-7.],\n",
              "        [-4.],\n",
              "        [-1.],\n",
              "        [ 2.],\n",
              "        [ 5.],\n",
              "        [ 8.],\n",
              "        [11.],\n",
              "        [14.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to make a prediction using our model:\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TR_ddlwxex2",
        "outputId": "7269025e-e1a3-49af-a1d5-b734337d1a6c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-5.473968]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred + 11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqjHv00xxdX",
        "outputId": "34794a84-1b54-4c38-84ec-db3cabb92b97"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.526032]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps in modelling with Tensorflow -\n",
        "1. Construct or import a pretrained model relevant to your problem.\n",
        "2. Compile the model (prepare it to be used with data)\n",
        "  * **Loss** - how wrong your model's predictions are compared to the truth labels (we need to minimise this).\n",
        "  * **Optimizer** - how your model should update its internal patterns to better its predictions.\n",
        "  * **Metrics** - human interpretable values for how well your model is doing.\n",
        "3. Fit the model to the training data so it can discover patterns\n",
        "  * **Epochs** - how many times the model will go through all of the training examples.\n",
        "4. Evaluate the model on the test data (how reliable are our model's predictions?)\n"
      ],
      "metadata": {
        "id": "WwHE5MjSyAKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our Model -\n",
        "we can improve our model by altering our steps we took to create a model.\n",
        "1. **Creating a Model** - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
        "3.**Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer ) or on more data (give the model more examples to learn from)."
      ],
      "metadata": {
        "id": "bVTtpT5Bz6fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "#1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "model.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz8pq8rq0OfH",
        "outputId": "4d889fbb-9844-4388-c904-937d806ea287"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 7.7856 - mae: 7.7856\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.6531 - mae: 7.6531\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.5206 - mae: 7.5206\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.4775 - mae: 7.4775\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4719 - mae: 7.4719\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4662 - mae: 7.4662\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4606 - mae: 7.4606\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4550 - mae: 7.4550\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4494 - mae: 7.4494\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.4438 - mae: 7.4438\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4381 - mae: 7.4381\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4325 - mae: 7.4325\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4269 - mae: 7.4269\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4213 - mae: 7.4213\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.4156 - mae: 7.4156\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4100 - mae: 7.4100\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.4044 - mae: 7.4044\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.3988 - mae: 7.3988\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.3931 - mae: 7.3931\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.3875 - mae: 7.3875\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.3819 - mae: 7.3819\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3763 - mae: 7.3763\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.3706 - mae: 7.3706\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.3650 - mae: 7.3650\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.3594 - mae: 7.3594\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3538 - mae: 7.3538\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3481 - mae: 7.3481\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.3425 - mae: 7.3425\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.3369 - mae: 7.3369\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.3313 - mae: 7.3313\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.3256 - mae: 7.3256\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3200 - mae: 7.3200\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3144 - mae: 7.3144\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3088 - mae: 7.3088\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.3031 - mae: 7.3031\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.2975 - mae: 7.2975\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2919 - mae: 7.2919\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2863 - mae: 7.2863\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2806 - mae: 7.2806\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.2413 - mae: 7.2413\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1963 - mae: 7.1963\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1738 - mae: 7.1738\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.1513 - mae: 7.1513\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1288 - mae: 7.1288\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1063 - mae: 7.1063\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9375 - mae: 6.9375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f85160738e0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGVUhoyQ0Obe",
        "outputId": "dfb34688-aa06-4faa-f45f-8f91183ee10d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
              " array([[-7.],\n",
              "        [-4.],\n",
              "        [-1.],\n",
              "        [ 2.],\n",
              "        [ 5.],\n",
              "        [ 8.],\n",
              "        [11.],\n",
              "        [14.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved ...\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udZL7mmm3ojJ",
        "outputId": "3114c5a0-46ee-4c68-acb6-564b7bc27320"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 108ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30.298334]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if we can make another change to improve our model -\n",
        "\n",
        "#1. Create the model (this time with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation = \"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the model\n",
        "model.compile( loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "               metrics=[\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "model.fit(X,y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P-LsmAw31Ze",
        "outputId": "9f3b7f23-3f17-4279-d50f-bcad50bfc80e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 13.1693 - mae: 13.1693\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 12.7132 - mae: 12.7132\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 12.2538 - mae: 12.2538\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.7890 - mae: 11.7890\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 11.3119 - mae: 11.3119\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.8212 - mae: 10.8212\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10.3393 - mae: 10.3393\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.8317 - mae: 9.8317\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.2941 - mae: 9.2941\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.7229 - mae: 8.7229\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.1124 - mae: 8.1124\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.4573 - mae: 7.4573\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.7999 - mae: 6.7999\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.0826 - mae: 6.0826\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.3080 - mae: 5.3080\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.4631 - mae: 4.4631\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9921 - mae: 3.9921\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8968 - mae: 3.8968\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9680 - mae: 3.9680\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9026 - mae: 3.9026\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9453 - mae: 3.9453\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9165 - mae: 3.9165\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9255 - mae: 3.9255\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9234 - mae: 3.9234\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9008 - mae: 3.9008\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9304 - mae: 3.9304\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8760 - mae: 3.8760\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9376 - mae: 3.9376\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8727 - mae: 3.8727\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9286 - mae: 3.9286\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8867 - mae: 3.8867\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9038 - mae: 3.9038\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8938 - mae: 3.8938\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8789 - mae: 3.8789\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9011 - mae: 3.9011\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.8538 - mae: 3.8538\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.9084 - mae: 3.9084\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.8477 - mae: 3.8477\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9060 - mae: 3.9060\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8581 - mae: 3.8581\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8810 - mae: 3.8810\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8654 - mae: 3.8654\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8558 - mae: 3.8558\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8728 - mae: 3.8728\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8304 - mae: 3.8304\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8816 - mae: 3.8816\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8232 - mae: 3.8232\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8821 - mae: 3.8821\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8306 - mae: 3.8306\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8568 - mae: 3.8568\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8381 - mae: 3.8381\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8314 - mae: 3.8314\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8457 - mae: 3.8457\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8058 - mae: 3.8058\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8588 - mae: 3.8588\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7966 - mae: 3.7966\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8570 - mae: 3.8570\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8042 - mae: 3.8042\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8314 - mae: 3.8314\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8119 - mae: 3.8119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8057 - mae: 3.8057\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8198 - mae: 3.8198\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7827 - mae: 3.7827\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8347 - mae: 3.8347\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7712 - mae: 3.7712\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8306 - mae: 3.8306\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7789 - mae: 3.7789\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8047 - mae: 3.8047\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7869 - mae: 3.7869\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7788 - mae: 3.7788\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7950 - mae: 3.7950\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7592 - mae: 3.7592\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8100 - mae: 3.8100\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7468 - mae: 3.7468\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8030 - mae: 3.8030\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7547 - mae: 3.7547\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7768 - mae: 3.7768\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7629 - mae: 3.7629\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7505 - mae: 3.7505\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7746 - mae: 3.7746\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7303 - mae: 3.7303\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7864 - mae: 3.7864\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7234 - mae: 3.7234\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7740 - mae: 3.7740\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7316 - mae: 3.7316\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7475 - mae: 3.7475\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7399 - mae: 3.7399\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7219 - mae: 3.7219\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7553 - mae: 3.7553\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7003 - mae: 3.7003\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7638 - mae: 3.7638\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7010 - mae: 3.7010\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7437 - mae: 3.7437\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7094 - mae: 3.7094\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7169 - mae: 3.7169\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7180 - mae: 3.7180\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6945 - mae: 3.6945\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7335 - mae: 3.7335\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6712 - mae: 3.6712\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7390 - mae: 3.7390\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f85161429e0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's remind ourselves of the data -\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQag8GIU5z5Q",
        "outputId": "04d75129-8765-4409-8148-3829265d4a7c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
              " array([[-7.],\n",
              "        [-4.],\n",
              "        [-1.],\n",
              "        [ 2.],\n",
              "        [ 5.],\n",
              "        [ 8.],\n",
              "        [11.],\n",
              "        [14.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try to predict the y value -\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGs_4dJL6H9B",
        "outputId": "10fbf3b5-be77-481b-afbe-91cd51469d1a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 83ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32.15468]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if we can make another change to improve our model - now No activation function and reduced hidden units.\n",
        "\n",
        "#1. Create the model (this time with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation = None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the model\n",
        "model.compile( loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "               metrics=[\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "model.fit(X,y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6mWa2_n6R7G",
        "outputId": "4596c6b6-ea29-4ae1-9540-e7ce00f9f1ae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 14.2068 - mae: 14.2068\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.7185 - mae: 13.7185\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.2328 - mae: 13.2328\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.7469 - mae: 12.7469\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.2585 - mae: 12.2585\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.7651 - mae: 11.7651\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.2639 - mae: 11.2639\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.7526 - mae: 10.7526\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.2283 - mae: 10.2283\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6886 - mae: 9.6886\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1305 - mae: 9.1305\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5512 - mae: 8.5512\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.9478 - mae: 7.9478\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3172 - mae: 7.3172\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1708 - mae: 7.1708\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1508 - mae: 7.1508\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1308 - mae: 7.1308\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1107 - mae: 7.1107\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0905 - mae: 7.0905\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0702 - mae: 7.0702\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0499 - mae: 7.0499\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0296 - mae: 7.0296\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.0091 - mae: 7.0091\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9886 - mae: 6.9886\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9748 - mae: 6.9748\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9607 - mae: 6.9607\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9405 - mae: 6.9405\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9203 - mae: 6.9203\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8999 - mae: 6.8999\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8795 - mae: 6.8795\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8590 - mae: 6.8590\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8383 - mae: 6.8383\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8176 - mae: 6.8176\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7968 - mae: 6.7968\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7758 - mae: 6.7758\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7548 - mae: 6.7548\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7336 - mae: 6.7336\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7123 - mae: 6.7123\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.6909 - mae: 6.6909\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6693 - mae: 6.6693\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.6476 - mae: 6.6476\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6258 - mae: 6.6258\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6039 - mae: 6.6039\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.5818 - mae: 6.5818\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.5595 - mae: 6.5595\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.5372 - mae: 6.5372\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.5146 - mae: 6.5146\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.4919 - mae: 6.4919\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.4691 - mae: 6.4691\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.4576 - mae: 6.4576\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4434 - mae: 6.4434\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4207 - mae: 6.4207\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3977 - mae: 6.3977\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3746 - mae: 6.3746\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3514 - mae: 6.3514\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.3279 - mae: 6.3279\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3042 - mae: 6.3042\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.2804 - mae: 6.2804\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.2564 - mae: 6.2564\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.2321 - mae: 6.2321\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.2077 - mae: 6.2077\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.1830 - mae: 6.1830\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.1582 - mae: 6.1582\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.1331 - mae: 6.1331\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.1078 - mae: 6.1078\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.0823 - mae: 6.0823\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.0565 - mae: 6.0565\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0314 - mae: 6.0314\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.0299 - mae: 6.0299\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.0041 - mae: 6.0041\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.9780 - mae: 5.9780\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.9516 - mae: 5.9516\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.9250 - mae: 5.9250\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.8982 - mae: 5.8982\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.8711 - mae: 5.8711\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.8437 - mae: 5.8437\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.8160 - mae: 5.8160\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.7881 - mae: 5.7881\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7599 - mae: 5.7599\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.7314 - mae: 5.7314\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.7026 - mae: 5.7026\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6735 - mae: 5.6735\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.6441 - mae: 5.6441\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6212 - mae: 5.6212\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6197 - mae: 5.6197\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.7277 - mae: 5.7277\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.5506 - mae: 5.5506\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5202 - mae: 5.5202\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.4894 - mae: 5.4894\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4583 - mae: 5.4583\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4269 - mae: 5.4269\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3951 - mae: 5.3951\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3630 - mae: 5.3630\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3305 - mae: 5.3305\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3048 - mae: 5.3048\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.3464 - mae: 5.3464\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4146 - mae: 5.4146\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2267 - mae: 5.2267\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1929 - mae: 5.1929\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.1587 - mae: 5.1587\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f8522e0fa90>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try to predict the y value -\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfL1N_h-7VMv",
        "outputId": "52d2d403-0545-4858-b851-34c74ff8db8b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8522e39fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.831583]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if we can make another change to improve our model - now we change the optimizer to ADAM optimizer\n",
        "\n",
        "#1. Create the model (this time with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation = None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the model\n",
        "model.compile( loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=[\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "model.fit(X,y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXYZpyV07aTh",
        "outputId": "9de5b057-7ab3-4b75-c0c8-fcb6910bb4b5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 13.4946 - mae: 13.4946\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 13.4218 - mae: 13.4218\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.3491 - mae: 13.3491\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 13.2763 - mae: 13.2763\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.2035 - mae: 13.2035\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.1307 - mae: 13.1307\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.0579 - mae: 13.0579\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.9850 - mae: 12.9850\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.9121 - mae: 12.9121\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.8391 - mae: 12.8391\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.7661 - mae: 12.7661\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.6931 - mae: 12.6931\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.6200 - mae: 12.6200\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.5468 - mae: 12.5468\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.4735 - mae: 12.4735\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.4002 - mae: 12.4002\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.3269 - mae: 12.3269\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.2534 - mae: 12.2534\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.1798 - mae: 12.1798\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.1062 - mae: 12.1062\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.0324 - mae: 12.0324\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.9585 - mae: 11.9585\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.8845 - mae: 11.8845\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.8104 - mae: 11.8104\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.7361 - mae: 11.7361\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.6617 - mae: 11.6617\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.5871 - mae: 11.5871\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.5124 - mae: 11.5124\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.4374 - mae: 11.4374\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.3623 - mae: 11.3623\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.2870 - mae: 11.2870\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.2115 - mae: 11.2115\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.1357 - mae: 11.1357\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.0598 - mae: 11.0598\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.9836 - mae: 10.9836\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.9072 - mae: 10.9072\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10.8305 - mae: 10.8305\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.7536 - mae: 10.7536\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.6764 - mae: 10.6764\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10.5989 - mae: 10.5989\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.5212 - mae: 10.5212\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.4432 - mae: 10.4432\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.3649 - mae: 10.3649\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.2863 - mae: 10.2863\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.2074 - mae: 10.2074\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.1281 - mae: 10.1281\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.0486 - mae: 10.0486\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.9687 - mae: 9.9687\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.8885 - mae: 9.8885\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.8079 - mae: 9.8079\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.7270 - mae: 9.7270\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.6458 - mae: 9.6458\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.5642 - mae: 9.5642\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.4822 - mae: 9.4822\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.3999 - mae: 9.3999\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.3171 - mae: 9.3171\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.2340 - mae: 9.2340\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.1505 - mae: 9.1505\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.0666 - mae: 9.0666\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.9823 - mae: 8.9823\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.8976 - mae: 8.8976\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8125 - mae: 8.8125\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.7270 - mae: 8.7270\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.6410 - mae: 8.6410\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.5546 - mae: 8.5546\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.4678 - mae: 8.4678\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.3805 - mae: 8.3805\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.2927 - mae: 8.2927\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.2046 - mae: 8.2046\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.1159 - mae: 8.1159\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.0268 - mae: 8.0268\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.9373 - mae: 7.9373\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.8472 - mae: 7.8472\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.7567 - mae: 7.7567\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.6657 - mae: 7.6657\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.5742 - mae: 7.5742\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4822 - mae: 7.4822\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3897 - mae: 7.3897\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2967 - mae: 7.2967\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2032 - mae: 7.2032\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1092 - mae: 7.1092\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0147 - mae: 7.0147\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9196 - mae: 6.9196\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8241 - mae: 6.8241\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.7637 - mae: 6.7637\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.7525 - mae: 6.7525\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7417 - mae: 6.7417\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7310 - mae: 6.7310\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7206 - mae: 6.7206\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.7103 - mae: 6.7103\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.7002 - mae: 6.7002\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6903 - mae: 6.6903\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.6805 - mae: 6.6805\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6708 - mae: 6.6708\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6612 - mae: 6.6612\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6523 - mae: 6.6523\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6616 - mae: 6.6616\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6642 - mae: 6.6642\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6606 - mae: 6.6606\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6516 - mae: 6.6516\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f8522fc8dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try to predict the y value -\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFHwLn7C7yvR",
        "outputId": "53516f9a-f2b9-4eb1-8930-1e12ea3dc661"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8522e3bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 118ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.970484]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if we can make another change to improve our model - now we change the optimizer to ADAM optimizer with learning rate\n",
        "\n",
        "#1. Create the model (this time with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation = None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the model\n",
        "model.compile( loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "               metrics=[\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "model.fit(X,y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWGN2KQD76qe",
        "outputId": "12149649-ee68-4241-b3e9-912c7b539ff3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 577ms/step - loss: 14.6372 - mae: 14.6372\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 14.5672 - mae: 14.5672\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 14.4973 - mae: 14.4973\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 14.4274 - mae: 14.4274\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 14.3576 - mae: 14.3576\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 14.2878 - mae: 14.2878\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 14.2182 - mae: 14.2182\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 14.1486 - mae: 14.1486\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 14.0791 - mae: 14.0791\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 14.0096 - mae: 14.0096\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 13.9402 - mae: 13.9402\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 13.8709 - mae: 13.8709\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.8016 - mae: 13.8016\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 13.7324 - mae: 13.7324\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 13.6632 - mae: 13.6632\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.5941 - mae: 13.5941\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 13.5250 - mae: 13.5250\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.4559 - mae: 13.4559\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.3869 - mae: 13.3869\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.3180 - mae: 13.3180\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.2491 - mae: 13.2491\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.1802 - mae: 13.1802\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.1113 - mae: 13.1113\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.0425 - mae: 13.0425\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 12.9736 - mae: 12.9736\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.9048 - mae: 12.9048\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.8360 - mae: 12.8360\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.7672 - mae: 12.7672\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.6984 - mae: 12.6984\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12.6296 - mae: 12.6296\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.5607 - mae: 12.5607\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.4919 - mae: 12.4919\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.4230 - mae: 12.4230\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.3541 - mae: 12.3541\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.2851 - mae: 12.2851\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12.2161 - mae: 12.2161\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.1470 - mae: 12.1470\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.0779 - mae: 12.0779\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.0087 - mae: 12.0087\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.9394 - mae: 11.9394\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.8701 - mae: 11.8701\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11.8006 - mae: 11.8006\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.7311 - mae: 11.7311\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.6614 - mae: 11.6614\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.5917 - mae: 11.5917\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.5218 - mae: 11.5218\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.4518 - mae: 11.4518\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.3816 - mae: 11.3816\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.3114 - mae: 11.3114\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.2409 - mae: 11.2409\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.1703 - mae: 11.1703\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.0996 - mae: 11.0996\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.0286 - mae: 11.0286\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.9575 - mae: 10.9575\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.8862 - mae: 10.8862\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.8147 - mae: 10.8147\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.7430 - mae: 10.7430\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.6711 - mae: 10.6711\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.5989 - mae: 10.5989\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.5265 - mae: 10.5265\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.4539 - mae: 10.4539\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.3811 - mae: 10.3811\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.3079 - mae: 10.3079\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.2345 - mae: 10.2345\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.1609 - mae: 10.1609\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.0869 - mae: 10.0869\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.0127 - mae: 10.0127\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.9381 - mae: 9.9381\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.8633 - mae: 9.8633\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.7881 - mae: 9.7881\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.7127 - mae: 9.7127\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6369 - mae: 9.6369\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.5607 - mae: 9.5607\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.4842 - mae: 9.4842\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.4074 - mae: 9.4074\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3301 - mae: 9.3301\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2526 - mae: 9.2526\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.1746 - mae: 9.1746\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0962 - mae: 9.0962\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.0175 - mae: 9.0175\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.9384 - mae: 8.9384\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.8588 - mae: 8.8588\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.7788 - mae: 8.7788\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6984 - mae: 8.6984\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.6176 - mae: 8.6176\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5364 - mae: 8.5364\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4547 - mae: 8.4547\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.3725 - mae: 8.3725\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.2899 - mae: 8.2899\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.2068 - mae: 8.2068\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.1232 - mae: 8.1232\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.0392 - mae: 8.0392\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.9547 - mae: 7.9547\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.8696 - mae: 7.8696\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.7841 - mae: 7.7841\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.6981 - mae: 7.6981\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.6116 - mae: 7.6116\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.5245 - mae: 7.5245\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4369 - mae: 7.4369\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3488 - mae: 7.3488\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f850e4fee60>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try to predict the y value -\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgOvSXg48ID0",
        "outputId": "a6099cff-386e-45bf-92a5-c83f85d45d38"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 123ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[25.912535]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a model\n",
        "\n",
        "In practice , typical workflow you'll go through when building neural network is:\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it ...\n",
        "```\n"
      ],
      "metadata": {
        "id": "6qoDRu9Y8tq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### When it comes to evaluation ... there are 3 words you should memorize:\n",
        "> \"visualize, Visualize, Visualize\"\n",
        "\n",
        "It is always a good idea to visualize -\n",
        "* The data - what data are we working with? What does it look like?\n",
        "* The model itself - What does our model look like?\n",
        "* The traning of a model - how does a model perform while it learns?\n",
        "* The predictions of the model - how do the predictions of a model line up against the ground truth (the original lables)."
      ],
      "metadata": {
        "id": "3OstztIM9GqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100,100,4)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIMcyf5D9GmS",
        "outputId": "93784d04-9901-4075-b439-694cda4f461e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels for the dataset -\n",
        "y = X+10\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcPmpQ5rAQ3L",
        "outputId": "50190388-bcad-40e6-cc19-6fb50ff50f3c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data:\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "NbTAimsvAdjk",
        "outputId": "e3736f4a-e78f-4344-8e62-fb93ce3e3b4f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f850e3fc460>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### The Three sets .."
      ],
      "metadata": {
        "id": "Sv7rpxZsAqmm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}